{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:01:40.237051Z",
     "start_time": "2021-01-24T16:01:40.206033Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from interpret.glassbox.ebm.utils import DPUtils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, StratifiedShuffleSplit\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EPS_RANGE = [0.5, 1, 2, 4, 8]\n",
    "DELTA = 1e-6\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 42\n",
    "N_SPLITS = 25\n",
    "CLASSIFICATION_SCORE = 'roc_auc'\n",
    "REGRESSION_SCORE = 'neg_root_mean_squared_error'\n",
    "ss = ShuffleSplit(n_splits=N_SPLITS, test_size=TEST_SIZE, random_state=SEED)\n",
    "\n",
    "# Initialize Results Frames\n",
    "\n",
    "dataset_meta = {}\n",
    "results = pd.DataFrame(columns=[\"dataset\", \"problem\", \"learner\", \"epsilon\", \"metric_name\", \"metric_value\"])\n",
    "noise_scales = pd.DataFrame(columns=[\"dataset\", \"problem\", \"learner\", \"n_rows\", \"n_features\", \"epsilon\", \"noise_scale\"])\n",
    "\n",
    "\n",
    "# Helper Functions \n",
    "\n",
    "\n",
    "def make_row(exp, learner_name, epsilon, metric_name, metric_value):\n",
    "    ''' In place update of results_df to add additional row. '''\n",
    "    row = {\"dataset\" : exp[\"dataset\"], \"problem\" : exp[\"problem\"], \n",
    "    \"learner\" : learner_name, \"epsilon\" : epsilon,\n",
    "    \"metric_name\" : metric_name, \"metric_value\" : metric_value}\n",
    "    return row\n",
    "\n",
    "def run_experiments(estimator, estimator_name, epsilon, exp, cv, scoring, n_jobs, use_numpy=True, output='dict'):\n",
    "    if use_numpy:\n",
    "        X, y = exp['X'].to_numpy(), exp['y'].to_numpy()\n",
    "    else:\n",
    "        X, y = exp['X'], exp['y']\n",
    "\n",
    "    results = cross_validate(estimator, X, y, scoring=scoring, cv=cv, n_jobs=n_jobs, error_score='raise')\n",
    "    metric = np.mean(results['test_score'])\n",
    "    metric_stdev = np.std(results['test_score'])\n",
    "\n",
    "    metric_str = f\"{metric:.3f} +- {metric_stdev:.3f}\"  # Print metric +/- metric_stdev\n",
    "\n",
    "    if isinstance(output, pd.DataFrame):\n",
    "        output.loc[len(output)] = make_row(exp, estimator_name, epsilon, scoring, metric_str)\n",
    "        return None\n",
    "    elif output == 'dict':\n",
    "        return results\n",
    "    else:\n",
    "        raise Exception('unknown output type')\n",
    "\n",
    "\n",
    "DPBOOST_PARAMETERS = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_iterations': 50,\n",
    "        'my_n_trees': 50,\n",
    "        'lambda_l2': 0.1,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_fraction':0.5,\n",
    "        'max_bin': 255,\n",
    "        'boost_method': 'DPBoost_2level',\n",
    "        'high_level_boost_round': 1,\n",
    "        'inner_boost_round': 50,\n",
    "        'balance_partition': 1,\n",
    "        'geo_clip': 1,\n",
    "        'verbose': 2,\n",
    "        'num_threads': 1,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classification Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:01:44.076312Z",
     "start_time": "2021-01-24T16:01:40.239468Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_adult, load_telco_churn, load_credit_fraud, load_pneumonia, onehotencode, make_categorical\n",
    "\n",
    "classification_datasets = []\n",
    "\n",
    "adult = load_adult()\n",
    "telco = load_telco_churn()\n",
    "credit = load_credit_fraud()\n",
    "pneumonia = load_pneumonia()\n",
    "\n",
    "classification_datasets.extend([adult, telco, pneumonia, credit])\n",
    "# classification_datasets.extend([adult])\n",
    "\n",
    "\n",
    "for dataset in classification_datasets:\n",
    "    dataset_meta.update({dataset['dataset'] : {'shape': dataset['df'].shape, 'domain': dataset['domain']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T17:20:20.795108Z",
     "start_time": "2021-01-24T16:01:44.079979Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1451038d8374d449fa6ab3cc241bae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult-income\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b405c81633a44d2eb99549d1b8d50f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "telco-churn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946b61808e634aa29ba8f3dd0dce6537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pneumonia\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0713378d6f294873bc473ceebc49e330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "credit-fraud\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d91deeb30f4585a4d502105c224eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>problem</th>\n",
       "      <th>learner</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.873 +- 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.875 +- 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.488 +- 0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.558 +- 0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.880 +- 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>4.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.465 +- 0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>8.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.969 +- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>8.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.969 +- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>8.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.546 +- 0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>8.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.556 +- 0.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset         problem              learner  epsilon metric_name  \\\n",
       "0   adult-income  classification         aEBM-classic      0.5     roc_auc   \n",
       "1   adult-income  classification             aEBM-gdp      0.5     roc_auc   \n",
       "2   adult-income  classification  Logistic Regression      0.5     roc_auc   \n",
       "3   adult-income  classification              DPBoost      0.5     roc_auc   \n",
       "4   adult-income  classification         aEBM-classic      1.0     roc_auc   \n",
       "..           ...             ...                  ...      ...         ...   \n",
       "75  credit-fraud  classification              DPBoost      4.0     roc_auc   \n",
       "76  credit-fraud  classification         aEBM-classic      8.0     roc_auc   \n",
       "77  credit-fraud  classification             aEBM-gdp      8.0     roc_auc   \n",
       "78  credit-fraud  classification  Logistic Regression      8.0     roc_auc   \n",
       "79  credit-fraud  classification              DPBoost      8.0     roc_auc   \n",
       "\n",
       "      metric_value  \n",
       "0   0.873 +- 0.007  \n",
       "1   0.875 +- 0.005  \n",
       "2   0.488 +- 0.125  \n",
       "3   0.558 +- 0.045  \n",
       "4   0.880 +- 0.006  \n",
       "..             ...  \n",
       "75  0.465 +- 0.142  \n",
       "76  0.969 +- 0.011  \n",
       "77  0.969 +- 0.011  \n",
       "78  0.546 +- 0.156  \n",
       "79  0.556 +- 0.145  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffprivlib.models import LogisticRegression as dpLogReg\n",
    "from interpret.glassbox import DPExplainableBoostingClassifier\n",
    "import lightgbm as lgb # DPBoost\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Classification Results Frame\n",
    "c_res = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"problem\", \"learner\", \"epsilon\", \"metric_name\", \"metric_value\"]\n",
    ")\n",
    "\n",
    "for exp in tqdm(classification_datasets):\n",
    "    print(exp['dataset'])\n",
    "    cat_exp = make_categorical(exp) # For DPBoost, which needs dtype as \"categorical\" to support natively\n",
    "    ohe_exp = onehotencode(exp)  # For LogisticRegression and NeuralNets that don't handle categoricals\n",
    "\n",
    "    for epsilon in tqdm(EPS_RANGE):\n",
    "        dp_ebm = DPExplainableBoostingClassifier(binning='private-quantile', epsilon=epsilon, delta=DELTA, composition='classic')\n",
    "        run_experiments(dp_ebm, \"aEBM-classic\", epsilon, exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, output=c_res)\n",
    "\n",
    "        dp_ebm_gdp = DPExplainableBoostingClassifier(binning='private-quantile', epsilon=epsilon, delta=DELTA, composition='gdp')\n",
    "        run_experiments(dp_ebm_gdp, \"aEBM-gdp\", epsilon, exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, output=c_res)\n",
    "\n",
    "        # Logistic Regression Section\n",
    "        lr = dpLogReg(epsilon=epsilon)\n",
    "        run_experiments(lr, \"Logistic Regression\", epsilon, ohe_exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, output=c_res)\n",
    "\n",
    "        # DPBoost Section -- doesn't support ShuffleSplit, have to do manually using same splits :/\n",
    "        dpb_scores = []\n",
    "        for train_index, test_index in ss.split(ohe_exp['X'].values):\n",
    "            X_train = ohe_exp['X'].iloc[train_index]\n",
    "            y_train = ohe_exp['y'].values[train_index]\n",
    "            X_test = ohe_exp['X'].iloc[test_index]\n",
    "            y_test = ohe_exp['y'].values[test_index]\n",
    "\n",
    "            data = lgb.Dataset(X_train, y_train)\n",
    "            dpb_train_params = {**DPBOOST_PARAMETERS, **{'total_budget': epsilon}}\n",
    "            dp_boost = lgb.train(dpb_train_params, data)\n",
    "\n",
    "            if CLASSIFICATION_SCORE == 'roc_auc':\n",
    "                dpb_score = roc_auc_score(y_test, dp_boost.predict(X_test))\n",
    "            elif CLASSIFICATION_SCORE == 'accuracy':\n",
    "                dpb_score = accuracy_score(y_test, np.round(np.clip(dp_boost.predict(X_test), 0, 1))) # Adapt DPBoost to classification\n",
    "            dpb_scores.append(dpb_score)\n",
    "\n",
    "        dpb_results = f\"{np.mean(dpb_scores):.3f} +- {np.std(dpb_scores):.3f}\"\n",
    "        c_res.loc[len(c_res)] = make_row(exp, \"DPBoost\", epsilon, CLASSIFICATION_SCORE, dpb_results)\n",
    "\n",
    "c_res\n",
    "# c_res.to_csv('classification_results.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T17:43:23.961931Z",
     "start_time": "2021-01-24T17:20:20.797955Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af673d8822f45cc8aa3070fe6c41e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult-income\n",
      "telco-churn\n",
      "pneumonia\n",
      "credit-fraud\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>problem</th>\n",
       "      <th>learner</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.873 +- 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.875 +- 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.488 +- 0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>0.5</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.558 +- 0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult-income</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.880 +- 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>classification</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>100.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.744 +- 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.836 +- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.965 +- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>100.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.922 +- 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>credit-fraud</td>\n",
       "      <td>classification</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.726 +- 0.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset         problem              learner  epsilon metric_name  \\\n",
       "0   adult-income  classification         aEBM-classic      0.5     roc_auc   \n",
       "1   adult-income  classification             aEBM-gdp      0.5     roc_auc   \n",
       "2   adult-income  classification  Logistic Regression      0.5     roc_auc   \n",
       "3   adult-income  classification              DPBoost      0.5     roc_auc   \n",
       "4   adult-income  classification         aEBM-classic      1.0     roc_auc   \n",
       "..           ...             ...                  ...      ...         ...   \n",
       "87     pneumonia  classification  Logistic Regression    100.0     roc_auc   \n",
       "88     pneumonia  classification              DPBoost    100.0     roc_auc   \n",
       "89  credit-fraud  classification         aEBM-classic    100.0     roc_auc   \n",
       "90  credit-fraud  classification  Logistic Regression    100.0     roc_auc   \n",
       "91  credit-fraud  classification              DPBoost    100.0     roc_auc   \n",
       "\n",
       "      metric_value  \n",
       "0   0.873 +- 0.007  \n",
       "1   0.875 +- 0.005  \n",
       "2   0.488 +- 0.125  \n",
       "3   0.558 +- 0.045  \n",
       "4   0.880 +- 0.006  \n",
       "..             ...  \n",
       "87  0.744 +- 0.014  \n",
       "88  0.836 +- 0.011  \n",
       "89  0.965 +- 0.011  \n",
       "90  0.922 +- 0.019  \n",
       "91  0.726 +- 0.099  \n",
       "\n",
       "[92 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build non-private versions of each model\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "epsilon = 100 # Easy sorting on dataset\n",
    "for exp in tqdm(classification_datasets):\n",
    "    print(exp['dataset'])\n",
    "    cat_exp = make_categorical(exp) # For DPBoost, which needs dtype as \"categorical\" to support natively\n",
    "    ohe_exp = onehotencode(exp)  # For LogisticRegression and NeuralNets that don't handle categoricals\n",
    "\n",
    "    ebm = ExplainableBoostingClassifier(binning='quantile', outer_bags=1, random_state=SEED)\n",
    "    run_experiments(ebm, \"aEBM-classic\", epsilon, exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, output=c_res)\n",
    "\n",
    "    # Logistic Regression Section\n",
    "    lr = LogisticRegression(random_state=SEED)\n",
    "    run_experiments(lr, \"Logistic Regression\", epsilon, ohe_exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, output=c_res)\n",
    "\n",
    "    # LightGBM (Non-Private DPBoost)\n",
    "    lgbm = LGBMClassifier(num_iterations=100, my_n_trees=100)  # Equal to default parameters in LightGBM\n",
    "    run_experiments(lgbm, \"DPBoost\", epsilon, cat_exp, ss, CLASSIFICATION_SCORE, n_jobs=-1, use_numpy=False, output=c_res)\n",
    "\n",
    "c_res.to_csv('classification_results.csv', index=None)\n",
    "c_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T17:43:24.288819Z",
     "start_time": "2021-01-24T17:43:23.963985Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_cal_housing, load_elevators, load_pol, load_wine_quality\n",
    "from datasets import onehotencode, make_categorical\n",
    "\n",
    "\n",
    "regression_datasets = []\n",
    "\n",
    "cal_housing = load_cal_housing()\n",
    "elevators = load_elevators()\n",
    "pol = load_pol()\n",
    "wine_quality = load_wine_quality()\n",
    "\n",
    "\n",
    "regression_datasets.extend([cal_housing, elevators, pol, wine_quality])\n",
    "\n",
    "\n",
    "for dataset in regression_datasets:\n",
    "    dataset_meta.update({dataset['dataset'] : dataset['df'].shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T18:00:01.947462Z",
     "start_time": "2021-01-24T17:43:24.291535Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8688770f6bfe49ed9c4b67c87e7d0078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal-housing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c33ca2832b4c7fb22029d0bdf5089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "elevators\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e29e67be8741dfa9c0bb9e5dc4aeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd1011e975f462cab01068ee59945fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wine-quality\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bc4561609f4c1fbffca8c0b58a1d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>problem</th>\n",
       "      <th>learner</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-85652.462 +- 2724.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-79967.205 +- 1929.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-111967.283 +- 1080.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-383072.269 +- 41952.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-78527.889 +- 1230.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.946 +- 0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.751 +- 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.733 +- 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.839 +- 0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.847 +- 0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset     problem            learner  epsilon  \\\n",
       "0    cal-housing  regression       aEBM-classic      0.5   \n",
       "1    cal-housing  regression           aEBM-gdp      0.5   \n",
       "2    cal-housing  regression  Linear Regression      0.5   \n",
       "3    cal-housing  regression            DPBoost      0.5   \n",
       "4    cal-housing  regression       aEBM-classic      1.0   \n",
       "..           ...         ...                ...      ...   \n",
       "75  wine-quality  regression            DPBoost      4.0   \n",
       "76  wine-quality  regression       aEBM-classic      8.0   \n",
       "77  wine-quality  regression           aEBM-gdp      8.0   \n",
       "78  wine-quality  regression  Linear Regression      8.0   \n",
       "79  wine-quality  regression            DPBoost      8.0   \n",
       "\n",
       "                    metric_name              metric_value  \n",
       "0   neg_root_mean_squared_error    -85652.462 +- 2724.267  \n",
       "1   neg_root_mean_squared_error    -79967.205 +- 1929.207  \n",
       "2   neg_root_mean_squared_error   -111967.283 +- 1080.877  \n",
       "3   neg_root_mean_squared_error  -383072.269 +- 41952.661  \n",
       "4   neg_root_mean_squared_error    -78527.889 +- 1230.833  \n",
       "..                          ...                       ...  \n",
       "75  neg_root_mean_squared_error           -0.946 +- 0.043  \n",
       "76  neg_root_mean_squared_error           -0.751 +- 0.013  \n",
       "77  neg_root_mean_squared_error           -0.733 +- 0.014  \n",
       "78  neg_root_mean_squared_error           -0.839 +- 0.035  \n",
       "79  neg_root_mean_squared_error           -0.847 +- 0.021  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffprivlib.models import LinearRegression as dpLinReg  \n",
    "from interpret.glassbox import DPExplainableBoostingRegressor\n",
    "import lightgbm as lgb # DPBoost\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Regression Results Frame\n",
    "r_res = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"problem\", \"learner\", \"epsilon\", \"metric_name\", \"metric_value\"]\n",
    ")\n",
    "\n",
    "\n",
    "for exp in tqdm(regression_datasets):\n",
    "    print(exp['dataset'])\n",
    "    cat_exp = make_categorical(exp) # For DPBoost, which needs dtype as \"categorical\" to support natively\n",
    "    ohe_exp = onehotencode(exp)  # For LinearRegression and NeuralNets that don't handle categoricals\n",
    "    for epsilon in tqdm(EPS_RANGE):\n",
    "        \n",
    "        # EBM Section\n",
    "        dp_ebm = DPExplainableBoostingRegressor(binning='private-quantile', epsilon=epsilon, delta=DELTA, composition='classic')\n",
    "        run_experiments(dp_ebm, \"aEBM-classic\", epsilon, exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "        dp_ebm_gdp = DPExplainableBoostingRegressor(binning='private-quantile', epsilon=epsilon, delta=DELTA, composition='gdp')\n",
    "        run_experiments(dp_ebm_gdp, \"aEBM-gdp\", epsilon, exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "        # Linear Regression Section\n",
    "        lr = dpLinReg(epsilon=epsilon)\n",
    "        run_experiments(lr, \"Linear Regression\", epsilon, exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "        # DPBoost Section -- doesn't support ShuffleSplit, have to do manually with same data\n",
    "        dpb_scores = []\n",
    "        for train_index, test_index in ss.split(ohe_exp['X'].values):\n",
    "            X_train = ohe_exp['X'].iloc[train_index]\n",
    "            y_train = ohe_exp['y'].values[train_index]\n",
    "            X_test = ohe_exp['X'].iloc[test_index]\n",
    "            y_test = ohe_exp['y'].values[test_index]\n",
    "\n",
    "            # Scale targets to [-1, 1] per DP boost Github guidance\n",
    "            scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "            _ = scaler.fit(y_train.reshape(-1,1))\n",
    "            dpb_y_train = scaler.transform(y_train.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "            data = lgb.Dataset(X_train, dpb_y_train)\n",
    "            dpb_train_params = {**DPBOOST_PARAMETERS, **{'total_budget': epsilon}}\n",
    "            dp_boost = lgb.train(dpb_train_params, data)\n",
    "\n",
    "            # Convert predictions back into original domain\n",
    "            dpb_preds = scaler.inverse_transform(dp_boost.predict(X_test).reshape(-1, 1))\n",
    "\n",
    "            dpb_rmse = np.sqrt(mean_squared_error(y_test, dpb_preds))\n",
    "            dpb_r2 = r2_score(y_test, dpb_preds)\n",
    "            dpb_scores.append(dpb_r2 if REGRESSION_SCORE == 'r2' else -1*dpb_rmse)\n",
    "            \n",
    "        dpb_results = f\"{np.mean(dpb_scores):.3f} +- {np.std(dpb_scores):.3f}\"\n",
    "        r_res.loc[len(r_res)] = make_row(exp, \"DPBoost\", epsilon, REGRESSION_SCORE, dpb_results)\n",
    "\n",
    "r_res\n",
    "# r_res.to_csv('regression_results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T18:09:27.956545Z",
     "start_time": "2021-01-24T18:00:01.949462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5507f2381b7d4b759e565e4be9776613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cal-housing\n",
      "elevators\n",
      "pol\n",
      "wine-quality\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>problem</th>\n",
       "      <th>learner</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-85652.462 +- 2724.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-gdp</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-79967.205 +- 1929.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-111967.283 +- 1080.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>0.5</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-383072.269 +- 41952.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cal-housing</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-78527.889 +- 1230.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pol</td>\n",
       "      <td>regression</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>100.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-30.464 +- 0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pol</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-4.703 +- 0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>aEBM-classic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.681 +- 0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>100.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.759 +- 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>wine-quality</td>\n",
       "      <td>regression</td>\n",
       "      <td>DPBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>-0.622 +- 0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset     problem            learner  epsilon  \\\n",
       "0    cal-housing  regression       aEBM-classic      0.5   \n",
       "1    cal-housing  regression           aEBM-gdp      0.5   \n",
       "2    cal-housing  regression  Linear Regression      0.5   \n",
       "3    cal-housing  regression            DPBoost      0.5   \n",
       "4    cal-housing  regression       aEBM-classic      1.0   \n",
       "..           ...         ...                ...      ...   \n",
       "87           pol  regression  Linear Regression    100.0   \n",
       "88           pol  regression            DPBoost    100.0   \n",
       "89  wine-quality  regression       aEBM-classic    100.0   \n",
       "90  wine-quality  regression  Linear Regression    100.0   \n",
       "91  wine-quality  regression            DPBoost    100.0   \n",
       "\n",
       "                    metric_name              metric_value  \n",
       "0   neg_root_mean_squared_error    -85652.462 +- 2724.267  \n",
       "1   neg_root_mean_squared_error    -79967.205 +- 1929.207  \n",
       "2   neg_root_mean_squared_error   -111967.283 +- 1080.877  \n",
       "3   neg_root_mean_squared_error  -383072.269 +- 41952.661  \n",
       "4   neg_root_mean_squared_error    -78527.889 +- 1230.833  \n",
       "..                          ...                       ...  \n",
       "87  neg_root_mean_squared_error          -30.464 +- 0.264  \n",
       "88  neg_root_mean_squared_error           -4.703 +- 0.228  \n",
       "89  neg_root_mean_squared_error           -0.681 +- 0.012  \n",
       "90  neg_root_mean_squared_error           -0.759 +- 0.015  \n",
       "91  neg_root_mean_squared_error           -0.622 +- 0.013  \n",
       "\n",
       "[92 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build non-private versions of each model\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "epsilon = 100 # Hack so Non-Private is at the bottom\n",
    "for exp in tqdm(regression_datasets):\n",
    "    print(exp['dataset'])\n",
    "    cat_exp = make_categorical(exp) # For DPBoost, which needs dtype as \"categorical\" to support natively\n",
    "    ohe_exp = onehotencode(exp)  # For LinearRegression and NeuralNets that don't handle categoricals\n",
    "\n",
    "    ebm = ExplainableBoostingRegressor(binning='quantile', outer_bags=1, random_state=SEED)\n",
    "    run_experiments(ebm, \"aEBM-classic\", epsilon, exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "    # Linear Regression Section\n",
    "    lr = LinearRegression()\n",
    "    run_experiments(lr, \"Linear Regression\", epsilon, ohe_exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "    # Non-Private DPBoost Section\n",
    "    lgbm = LGBMRegressor(num_iterations=100, my_n_trees=100)  # Equal to default parameters in LightGBM\n",
    "    run_experiments(lgbm, \"DPBoost\", epsilon, cat_exp, ss, REGRESSION_SCORE, n_jobs=-1, output=r_res)\n",
    "\n",
    "r_res.to_csv('regression_results.csv', index=None)\n",
    "r_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T18:19:47.129337Z",
     "start_time": "2021-01-24T18:19:47.093006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "            & {} & \\multicolumn{4}{l}{metric\\_value} \\\\\n",
      "            & learner &         DPBoost & Logistic Regression &    aEBM-classic &        aEBM-gdp \\\\\n",
      "dataset & epsilon &                 &                     &                 &                 \\\\\n",
      "\\midrule\n",
      "\\multirow{6}{*}{adult-income} & 0.5   &  0.558 +- 0.045 &      0.488 +- 0.125 &  0.873 +- 0.007 &  0.875 +- 0.005 \\\\\n",
      "            & 1.0   &  0.566 +- 0.034 &      0.471 +- 0.111 &  0.880 +- 0.006 &  0.883 +- 0.005 \\\\\n",
      "            & 2.0   &  0.629 +- 0.045 &      0.521 +- 0.109 &  0.886 +- 0.005 &  0.887 +- 0.004 \\\\\n",
      "            & 4.0   &  0.734 +- 0.019 &      0.549 +- 0.068 &  0.889 +- 0.004 &  0.889 +- 0.004 \\\\\n",
      "            & 8.0   &  0.805 +- 0.011 &      0.534 +- 0.070 &  0.890 +- 0.004 &  0.890 +- 0.004 \\\\\n",
      "            & 100.0 &  0.928 +- 0.003 &      0.603 +- 0.066 &  0.923 +- 0.003 &              -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{credit-fraud} & 0.5   &  0.442 +- 0.138 &      0.558 +- 0.076 &  0.959 +- 0.015 &  0.966 +- 0.012 \\\\\n",
      "            & 1.0   &  0.438 +- 0.114 &      0.544 +- 0.135 &  0.965 +- 0.014 &  0.966 +- 0.013 \\\\\n",
      "            & 2.0   &  0.467 +- 0.101 &      0.526 +- 0.118 &  0.969 +- 0.011 &  0.969 +- 0.011 \\\\\n",
      "            & 4.0   &  0.465 +- 0.142 &      0.539 +- 0.172 &  0.969 +- 0.011 &  0.969 +- 0.011 \\\\\n",
      "            & 8.0   &  0.556 +- 0.145 &      0.546 +- 0.156 &  0.969 +- 0.011 &  0.969 +- 0.011 \\\\\n",
      "            & 100.0 &  0.726 +- 0.099 &      0.922 +- 0.019 &  0.965 +- 0.011 &              -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{pneumonia} & 0.5   &  0.515 +- 0.054 &      0.463 +- 0.081 &  0.714 +- 0.036 &  0.793 +- 0.018 \\\\\n",
      "            & 1.0   &  0.505 +- 0.051 &      0.479 +- 0.071 &  0.789 +- 0.016 &  0.818 +- 0.012 \\\\\n",
      "            & 2.0   &  0.499 +- 0.046 &      0.495 +- 0.081 &  0.822 +- 0.012 &  0.830 +- 0.011 \\\\\n",
      "            & 4.0   &  0.567 +- 0.047 &      0.542 +- 0.038 &  0.834 +- 0.011 &  0.835 +- 0.010 \\\\\n",
      "            & 8.0   &  0.638 +- 0.036 &      0.529 +- 0.048 &  0.836 +- 0.010 &  0.837 +- 0.010 \\\\\n",
      "            & 100.0 &  0.836 +- 0.011 &      0.744 +- 0.014 &  0.847 +- 0.010 &              -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{telco-churn} & 0.5   &  0.484 +- 0.100 &      0.541 +- 0.227 &  0.812 +- 0.020 &  0.829 +- 0.014 \\\\\n",
      "            & 1.0   &  0.458 +- 0.088 &      0.479 +- 0.239 &  0.832 +- 0.013 &  0.835 +- 0.011 \\\\\n",
      "            & 2.0   &  0.534 +- 0.109 &      0.527 +- 0.236 &  0.837 +- 0.010 &  0.838 +- 0.012 \\\\\n",
      "            & 4.0   &  0.716 +- 0.067 &      0.615 +- 0.138 &  0.838 +- 0.011 &  0.839 +- 0.011 \\\\\n",
      "            & 8.0   &  0.787 +- 0.014 &      0.673 +- 0.105 &  0.839 +- 0.011 &  0.839 +- 0.011 \\\\\n",
      "            & 100.0 &  0.836 +- 0.008 &      0.844 +- 0.010 &  0.848 +- 0.009 &              -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_export = c_res[(c_res['metric_name'] == 'roc_auc')][['dataset', 'learner', 'epsilon', 'metric_value']]\n",
    "df_export = df_export.set_index(['dataset', 'epsilon']).pivot(columns='learner')\n",
    "print(df_export.to_latex(multirow=True, na_rep = \"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T18:19:47.800016Z",
     "start_time": "2021-01-24T18:19:47.764056Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "             & {} & \\multicolumn{4}{l}{metric\\_value} \\\\\n",
      "             & learner &                   DPBoost &        Linear Regression &            aEBM-classic &                aEBM-gdp \\\\\n",
      "dataset & epsilon &                           &                          &                         &                         \\\\\n",
      "\\midrule\n",
      "\\multirow{6}{*}{cal-housing} & 0.5   &  -383072.269 +- 41952.661 &  -111967.283 +- 1080.877 &  -85652.462 +- 2724.267 &  -79967.205 +- 1929.207 \\\\\n",
      "             & 1.0   &  -204277.173 +- 19350.722 &  -110241.222 +- 1101.717 &  -78527.889 +- 1230.833 &  -76827.355 +- 1470.026 \\\\\n",
      "             & 2.0   &   -122494.015 +- 7066.372 &  -109518.840 +- 1244.588 &  -75491.915 +- 1404.387 &  -74573.102 +- 1152.561 \\\\\n",
      "             & 4.0   &    -96336.577 +- 3043.443 &  -108882.248 +- 1370.641 &  -73967.071 +- 1028.464 &  -73754.682 +- 1022.504 \\\\\n",
      "             & 8.0   &    -90029.722 +- 2508.968 &  -107815.624 +- 1460.346 &  -73327.390 +- 1118.097 &   -73165.973 +- 955.614 \\\\\n",
      "             & 100.0 &     -47007.558 +- 885.923 &   -69850.761 +- 1164.052 &   -51644.446 +- 925.927 &                      -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{elevators} & 0.5   &           -0.051 +- 0.005 &          -4.671 +- 1.975 &         -0.010 +- 0.001 &         -0.006 +- 0.000 \\\\\n",
      "             & 1.0   &           -0.025 +- 0.002 &          -2.669 +- 1.214 &         -0.007 +- 0.000 &         -0.005 +- 0.000 \\\\\n",
      "             & 2.0   &           -0.013 +- 0.001 &          -1.384 +- 0.570 &         -0.006 +- 0.000 &         -0.005 +- 0.000 \\\\\n",
      "             & 4.0   &           -0.008 +- 0.000 &          -0.754 +- 0.202 &         -0.005 +- 0.000 &         -0.004 +- 0.000 \\\\\n",
      "             & 8.0   &           -0.006 +- 0.000 &          -0.410 +- 0.201 &         -0.004 +- 0.000 &         -0.004 +- 0.000 \\\\\n",
      "             & 100.0 &           -0.002 +- 0.000 &          -0.003 +- 0.000 &         -0.004 +- 0.000 &                      -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{pol} & 0.5   &          -78.190 +- 9.583 &         -31.326 +- 0.418 &        -35.156 +- 1.728 &        -30.988 +- 0.962 \\\\\n",
      "             & 1.0   &          -50.527 +- 5.482 &         -30.640 +- 0.288 &        -30.911 +- 1.014 &        -28.391 +- 0.585 \\\\\n",
      "             & 2.0   &          -47.511 +- 4.636 &         -30.500 +- 0.248 &        -27.616 +- 0.644 &        -26.303 +- 0.561 \\\\\n",
      "             & 4.0   &          -45.592 +- 2.942 &         -30.463 +- 0.256 &        -25.454 +- 0.389 &        -24.934 +- 0.332 \\\\\n",
      "             & 8.0   &          -45.435 +- 1.109 &         -30.459 +- 0.258 &        -24.625 +- 0.230 &        -24.313 +- 0.237 \\\\\n",
      "             & 100.0 &           -4.703 +- 0.228 &         -30.464 +- 0.264 &        -13.780 +- 0.667 &                      -- \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{6}{*}{wine-quality} & 0.5   &           -4.647 +- 0.390 &          -3.621 +- 1.740 &         -1.589 +- 0.132 &         -0.938 +- 0.036 \\\\\n",
      "             & 1.0   &           -2.151 +- 0.302 &          -2.133 +- 0.713 &         -1.181 +- 0.074 &         -0.841 +- 0.025 \\\\\n",
      "             & 2.0   &           -1.299 +- 0.092 &          -1.263 +- 0.322 &         -0.935 +- 0.042 &         -0.779 +- 0.018 \\\\\n",
      "             & 4.0   &           -0.946 +- 0.043 &          -0.940 +- 0.100 &         -0.807 +- 0.019 &         -0.746 +- 0.011 \\\\\n",
      "             & 8.0   &           -0.847 +- 0.021 &          -0.839 +- 0.035 &         -0.751 +- 0.013 &         -0.733 +- 0.014 \\\\\n",
      "             & 100.0 &           -0.622 +- 0.013 &          -0.759 +- 0.015 &         -0.681 +- 0.012 &                      -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_export = r_res[['dataset', 'learner', 'epsilon', 'metric_value']]\n",
    "df_export = df_export.set_index(['dataset', 'epsilon']).pivot(columns='learner')\n",
    "print(df_export.to_latex(multirow=True, na_rep = \"--\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
